{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import jacinle\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import jactorch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import Optional, Union, List, Dict\n",
    "from jacinle.config.environ_v2 import configs, set_configs\n",
    "from left.domain import create_domain_from_parsing\n",
    "from left.models.model import LeftModel\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import jacinle\n",
    "from jacinle.utils.container import GView\n",
    "from jacinle.config.environ_v2 import configs, set_configs, def_configs\n",
    "from concepts.benchmark.clevr.clevr_constants import g_attribute_concepts, g_relational_concepts\n",
    "from left.models.model import LeftModel\n",
    "import json\n",
    "import os\n",
    "\n",
    "from experiments.desc_clevr_nesycoco import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "### load glove file\n",
    "filename = \"./word_embeds/glove/glove.6B.300d.txt\"\n",
    "glove = {}\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove[word] = vector\n",
    "\n",
    "def get_synonym(word):\n",
    "    results = [glove[x] for x in word.split(\"_\") if x in glove]\n",
    "    np_results = np.array(results)\n",
    "    ##sum\n",
    "    if len(np_results) == 0:\n",
    "        return None\n",
    "    return np_results.sum(axis=0).reshape(1, -1)\n",
    "\n",
    "def get_cosine_similarity(token_1, token_2):\n",
    "    return cosine_similarity(get_synonym(token_1), get_synonym(token_2))[0][0]\n",
    "\n",
    "token_1 = \"congruent_shape\"\n",
    "token_2 = \"same_shape\"\n",
    "get_cosine_similarity(token_1, token_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import jacinle.io as io\n",
    "from os import path as osp\n",
    "\n",
    "og_parses = {}\n",
    "og_parses.update(io.load(\"data/clevr/val/questions-ncprogram-gt.pkl\"))\n",
    "syn_parses = {}\n",
    "syn_parses.update(io.load(\"data/clevr/val-syn-medium/questions-ncprogram-gt.pkl\"))\n",
    "data_dir = \"data/clevr/val/\"\n",
    "\n",
    "data_questions_json = osp.join(data_dir, 'questions.json')\n",
    "data_scenes_json = osp.join(data_dir, 'scenes.json')\n",
    "data_image_root = osp.join(data_dir, 'images')\n",
    "data_vocab_json = osp.join(data_dir, 'vocab.json')\n",
    "data_output_vocab_json = osp.join(data_dir, 'output-vocab.json')\n",
    "from left.domain import create_domain_from_parsing\n",
    "### limit the number of parses\n",
    "# all_parses = dict(list(all_parses.items())[:len(all_parses)//2])\n",
    "\n",
    "og_domain = create_domain_from_parsing(og_parses)\n",
    "syn_domain = create_domain_from_parsing(syn_parses)\n",
    "\n",
    "\n",
    "from concepts.benchmark.clevr.dataset import make_dataset\n",
    "dataset = make_dataset(\n",
    "    data_scenes_json,\n",
    "    data_questions_json,\n",
    "    data_image_root,\n",
    "    vocab_json=data_vocab_json,\n",
    "    output_vocab_json=data_output_vocab_json,\n",
    ")\n",
    "# train_dataset, validation_dataset = dataset.split_trainval(0.95)\n",
    "validation_dataset = dataset\n",
    "\n",
    "print(\"Finsihed loading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 96\n",
    "validation_dataloader = validation_dataset.make_dataloader(batch_size, shuffle=True, drop_last=False, nr_workers=num_workers)\n",
    "\n",
    "from jacinle.config.g import g\n",
    "g.concept_mapping = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jactorch.io import state_dict, load_state_dict\n",
    "from left.data.referit3d.vocabulary import Vocabulary\n",
    "from jactorch.train import TrainerEnv\n",
    "from jactorch.optim import AdamW\n",
    "from jactorch.cuda.copy import async_copy_to\n",
    "\n",
    "vocab = Vocabulary()\n",
    "og_model = make_model(None, og_domain, og_parses, validation_dataset.output_vocab if hasattr(validation_dataset, 'output_vocab') else validation_dataset.unwrapped.output_vocab, custom_transfer=None)\n",
    "og_model.cuda()\n",
    "trainable_parameters = filter(lambda x: x.requires_grad, og_model.parameters())\n",
    "optimizer = AdamW(trainable_parameters, 0.001 , weight_decay=1e-2)\n",
    "og_trainer = TrainerEnv(og_model, optimizer)\n",
    "\n",
    "syn_model = make_model(None, syn_domain, syn_parses, validation_dataset.output_vocab if hasattr(validation_dataset, 'output_vocab') else validation_dataset.unwrapped.output_vocab, custom_transfer=None)\n",
    "syn_model.cuda()\n",
    "trainable_parameters = filter(lambda x: x.requires_grad, syn_model.parameters())\n",
    "optimizer = AdamW(trainable_parameters, 0.001 , weight_decay=1e-2)\n",
    "syn_trainer = TrainerEnv(syn_model, optimizer)\n",
    "\n",
    "\n",
    "filename = \"[path to the model]\"\n",
    "\n",
    "og_trainer.load_checkpoint(filename)\n",
    "og_model.eval()\n",
    "\n",
    "syn_trainer.load_checkpoint(filename)\n",
    "syn_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(validation_dataloader)\n",
    "data_all = [next(iterator) for _ in range(200)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from generate_clevr_syn import validation_convert_dict\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau, pearsonr\n",
    "from jacinle.utils.tqdm import tqdm_pbar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the group meters (if needed by your environment)\n",
    "group_meters = jacinle.GroupMeters()\n",
    "group_meters.reset()\n",
    "\n",
    "# List to hold the concepts and their corresponding synonyms\n",
    "replaced_concepts = []\n",
    "for concept in validation_convert_dict:\n",
    "    replaced_concepts.extend(validation_convert_dict[concept])\n",
    "\n",
    "# Dictionaries to hold Kendall's Tau and p-values for each synonym pair\n",
    "all_pearsons = {x: [] for x in replaced_concepts}\n",
    "all_p_values = {x: [] for x in replaced_concepts}\n",
    "\n",
    "# # Loop through the validation dataloader\n",
    "# with tqdm_pbar(total=len(validation_dataloader)) as pbar:\n",
    "#     for (index, feed_dict) in enumerate(validation_dataloader):\n",
    "\n",
    "with tqdm_pbar(total=len(data_all)) as pbar:\n",
    "    for (index, feed_dict) in enumerate(data_all):\n",
    "\n",
    "        # Perform the necessary data transfer to GPU (or the appropriate device)\n",
    "        feed_dict = async_copy_to(feed_dict, 0)\n",
    "\n",
    "        # Evaluate the original and synonym models\n",
    "        og_output_dict, og_extra_info = og_trainer.evaluate(feed_dict)\n",
    "        syn_output_dict, syn_extra_info = syn_trainer.evaluate(feed_dict)\n",
    "\n",
    "        # Loop through the execution traces to compare tensors\n",
    "        for i in range(len(og_output_dict[\"execution_traces\"][0])):\n",
    "            if len(str(og_output_dict[\"execution_traces\"][0][i][0])) > 6:\n",
    "                og_fn = str(og_output_dict[\"execution_traces\"][0][i][0])\n",
    "                tensor_values = np.array(og_output_dict[\"execution_traces\"][0][i][1].tensor.detach().cpu().numpy())\n",
    "                syn_fn = str(syn_output_dict[\"execution_traces\"][0][i][0])\n",
    "                syn_predicate = syn_fn.split(\"(\")[0].replace(\"_Object\", \"\")\n",
    "                og_predicate = og_fn.split(\"(\")[0].replace(\"_Object\", \"\")\n",
    "                \n",
    "                # Check for predicate mismatch and calculate Kendall's Tau\n",
    "                if syn_predicate != og_predicate and syn_predicate in all_pearsons:\n",
    "                    syn_tensor_values = np.array(syn_output_dict[\"execution_traces\"][0][i][1].tensor.detach().cpu().numpy())\n",
    "                    # if np.isnan(syn_tensor_values).any() or np.isnan(tensor_values).any() or np.inf in syn_tensor_values or np.inf in tensor_values:\n",
    "                    #     continue\n",
    "                    # syn_tensor_values = (syn_tensor_values - syn_tensor_values.min()) / (syn_tensor_values.max() - syn_tensor_values.min())            \n",
    "                    corr, p_value = pearsonr(syn_tensor_values, tensor_values)\n",
    "\n",
    "                    if np.isnan(corr) or np.isnan(p_value):\n",
    "                        continue\n",
    "                    \n",
    "                    # Append the results to the corresponding lists\n",
    "                    all_pearsons[syn_predicate].append(corr)\n",
    "                    all_p_values[syn_predicate].append(p_value)\n",
    "        \n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Break the loop if the index reaches 4000 (as per your original code)\n",
    "        if index == 10000:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store data for plotting\n",
    "cosine_similarities = []\n",
    "pearson_values = []\n",
    "syn_pairs = []\n",
    "\n",
    "# Compute and print the final results\n",
    "for key, syns in validation_convert_dict.items():\n",
    "    for syn in syns:\n",
    "        cosine_similarity_score = get_cosine_similarity(key, syn)\n",
    "        mean_tau = np.mean(all_pearsons[syn])\n",
    "        mean_p_value = np.mean(all_p_values[syn])\n",
    "        count = len(all_pearsons[syn])\n",
    "        \n",
    "        print(key, syn, \"get_cosine_similarity\", cosine_similarity_score, \"pearson-value\", mean_tau, \"p-value\", mean_p_value, count)\n",
    "        \n",
    "        # Store the values for plotting\n",
    "        cosine_similarities.append(cosine_similarity_score)\n",
    "        pearson_values.append(mean_tau)\n",
    "        syn_pairs.append(f\"{key}-{syn}\")\n",
    "\n",
    "# Plot the scatter plot with synonyms as labels\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each point with its corresponding synonym token pair\n",
    "for i in range(len(cosine_similarities)):\n",
    "    plt.scatter(cosine_similarities[i], pearson_values[i], color='blue')\n",
    "    plt.text(cosine_similarities[i] + 0.01, pearson_values[i] + 0.01, syn_pairs[i], fontsize=9)\n",
    "\n",
    "# Calculate Pearson correlation coefficient for the plot title\n",
    "pearson_corr, cor_p_value = pearsonr(cosine_similarities, pearson_values)\n",
    "print(\"Pearson Correlation:\", pearson_corr, cor_p_value)\n",
    "### x and y should have same scale\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(-0.2, 1.1)\n",
    "\n",
    "## make the font bigger\n",
    "\n",
    "\n",
    "plt.title(f\"Scatter Plot of Cosine Similarity vs Tau's Value\\nPearson Correlation: {pearson_corr:.2f}\")\n",
    "plt.xlabel(\"Cosine Similarity\")\n",
    "plt.ylabel(\"Tau's Value\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "iterator = iter(validation_dataloader)\n",
    "data_all = [next(iterator) for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "## Open a real image from address draw bouding boxes for objects\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import json\n",
    "# plt.close()\n",
    "from copy import deepcopy\n",
    "from reascan import get_image\n",
    "feed_dict = data_all[wrong_indices[21]]\n",
    "feed_dict = async_copy_to(feed_dict, 0)\n",
    "\n",
    "print(feed_dict)\n",
    "q = feed_dict[\"question_raw\"][0]\n",
    "\n",
    "og_output_dict, og_extra_info = og_trainer.evaluate(feed_dict)\n",
    "syn_output_dict, syn_extra_info = syn_trainer.evaluate(feed_dict)\n",
    "all_taus = {x:[] for x in replaced_concepts}\n",
    "all_p_values = {x:[] for x in replaced_concepts}\n",
    "image = Image.open(osp.join(data_image_root, feed_dict[\"image_filename\"][0])).convert('RGB')\n",
    "print(feed_dict[\"question_raw\"])\n",
    "for i in range(len(og_output_dict[\"execution_traces\"][0])):\n",
    "    \n",
    "    if len(str(og_output_dict[\"execution_traces\"][0][i][0])) > 6:\n",
    "        tensor_values = np.array(og_output_dict[\"execution_traces\"][0][i][1].tensor.detach().cpu().numpy())\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "        og_fn = str(og_output_dict[\"execution_traces\"][0][i][0])\n",
    "        for obj_index,obj in enumerate(feed_dict[\"objects_raw\"][0]):\n",
    "            # Create a Rectangle patch\n",
    "            rect = patches.Rectangle((obj[0], obj[1]), obj[2] - obj[0], obj[3] - obj[1], linewidth=1, edgecolor='r', facecolor=\"none\")\n",
    "            ax.add_patch(rect)\n",
    "            try:\n",
    "                text = f\"{obj_index} {round(float(tensor_values[obj_index]),4)} \"\n",
    "            except:\n",
    "                print(\"##\"*100)\n",
    "                text = f\"{obj_index} {tensor_values} \"\n",
    "            ax.text(obj[0], obj[1], text, color='white', fontsize=10, bbox=dict(facecolor='red', alpha=0.5))\n",
    "        plt.title(str(og_output_dict[\"execution_traces\"][0][i][0]))\n",
    "        plt.show()\n",
    "        print(tensor_values)\n",
    "        syn_fn = str(syn_output_dict[\"execution_traces\"][0][i][0])\n",
    "        if og_fn != syn_fn and syn_fn.count(\"(\") == 1:\n",
    "            syn_tensor_values = np.array(syn_output_dict[\"execution_traces\"][0][i][1].tensor.detach().cpu().numpy())\n",
    "            \n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(image)\n",
    "            for obj_index,obj in enumerate(feed_dict[\"objects_raw\"][0]):\n",
    "                rect = patches.Rectangle((obj[0], obj[1]), obj[2] - obj[0], obj[3] - obj[1], linewidth=1, edgecolor='r', facecolor=\"none\")\n",
    "                ax.add_patch(rect)\n",
    "                try:\n",
    "                    text = f\"{obj_index} {round(float(syn_tensor_values[obj_index]),4)} \"\n",
    "                except:\n",
    "                    print(\"##\"*100)\n",
    "                    text = f\"{obj_index} {syn_tensor_values} \"\n",
    "                ax.text(obj[0], obj[1], text, color='white', fontsize=10, bbox=dict(facecolor='red', alpha=0.5))\n",
    "            plt.title(\"###########\" + str(syn_output_dict[\"execution_traces\"][0][i][0]))\n",
    "            plt.show()\n",
    "            print(syn_tensor_values)\n",
    "            tau, p_value = kendalltau(syn_tensor_values, tensor_values)\n",
    "            predicate = syn_fn.split(\"(\")[0]\n",
    "            all_taus.append(tau)\n",
    "            all_p_values.append(p_value)\n",
    "    \n",
    "\n",
    "print(all_taus)\n",
    "print(all_p_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
